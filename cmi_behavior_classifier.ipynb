{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYMbf9mY84ya"
      },
      "outputs": [],
      "source": [
        "# Delete all kaggle json files\n",
        "!rm -f kaggle*.json\n",
        "\n",
        "# Delete the dataset zip\n",
        "!rm -f cmi-detect-behavior-with-sensor-data.zip\n",
        "\n",
        "# Delete the folders\n",
        "!rm -rf cmi_data sample_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "ELjH7YoF3UyI",
        "outputId": "e5d7f261-3174-4800-fd8e-c37330f8db8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ca5d519-3ca9-42a4-bec6-c50663eb1794\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ca5d519-3ca9-42a4-bec6-c50663eb1794\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload your kaggle.json again if runtime was reset\n",
        "\n",
        "!mkdir -p ~/.config/kaggle\n",
        "!cp kaggle.json ~/.config/kaggle/\n",
        "!chmod 600 ~/.config/kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtP0wbWQ8dKG",
        "outputId": "9fc04fb4-40b0-4ca4-a386-d08c9f299f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading cmi-detect-behavior-with-sensor-data.zip to /content\n",
            " 62% 110M/178M [00:00<00:00, 1.15GB/s]\n",
            "100% 178M/178M [00:00<00:00, 1.16GB/s]\n",
            "Train shape: (574945, 341)\n",
            "\n",
            "Time steps per sequence:\n",
            "count    8151.000000\n",
            "mean       70.536744\n",
            "std        35.389879\n",
            "min        29.000000\n",
            "25%        51.000000\n",
            "50%        59.000000\n",
            "75%        78.000000\n",
            "max       700.000000\n",
            "dtype: float64\n",
            "\n",
            "Total sensor features: 332\n",
            "Sample sensor columns: ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download & unzip\n",
        "!kaggle competitions download -c cmi-detect-behavior-with-sensor-data\n",
        "!unzip -q cmi-detect-behavior-with-sensor-data.zip -d cmi_data/\n",
        "\n",
        "# Step 2: Load the data\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"cmi_data/train.csv\")\n",
        "\n",
        "# Step 3: Show the shape\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "\n",
        "# Step 4: Preview sensor structure\n",
        "sensor_start_col = train_df.columns.get_loc('acc_x')\n",
        "sensor_cols = train_df.columns[sensor_start_col:]\n",
        "sequence_lengths = train_df.groupby('sequence_id').size()\n",
        "num_features = len(sensor_cols)\n",
        "max_timesteps = sequence_lengths.max()\n",
        "min_timesteps = sequence_lengths.min()\n",
        "\n",
        "print(\"\\nTime steps per sequence:\")\n",
        "print(sequence_lengths.describe())\n",
        "print(f\"\\nTotal sensor features: {num_features}\")\n",
        "print(f\"Sample sensor columns: {sensor_cols[:5].tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYAby_RNCdcK"
      },
      "outputs": [],
      "source": [
        "# # STEP 1: Install and import dependencies\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # STEP 2: Load data\n",
        "# train_df = pd.read_csv(\"cmi_data/train.csv\")\n",
        "\n",
        "# # STEP 3: Sensor & label columns\n",
        "# sensor_start_col = train_df.columns.get_loc('acc_x')\n",
        "# sensor_cols = train_df.columns[sensor_start_col:]\n",
        "# label_df = train_df[['sequence_id', 'behavior']].drop_duplicates()\n",
        "\n",
        "# # STEP 4: Encode labels\n",
        "# le = LabelEncoder()\n",
        "# label_df['label'] = le.fit_transform(label_df['behavior'])\n",
        "\n",
        "# # STEP 5: Build sequences and normalize\n",
        "# sequences = []\n",
        "# labels = []\n",
        "\n",
        "# # Collect all sequences for scaling\n",
        "# raw_sequences = []\n",
        "# for seq_id in label_df['sequence_id']:\n",
        "#     seq_data = train_df[train_df['sequence_id'] == seq_id][sensor_cols].values\n",
        "#     raw_sequences.append(seq_data)\n",
        "#     labels.append(label_df[label_df['sequence_id'] == seq_id]['label'].values[0])\n",
        "\n",
        "# # Fit scaler on all sensor data\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(np.vstack(raw_sequences))\n",
        "\n",
        "# # Normalize each sequence\n",
        "# normalized_sequences = [scaler.transform(seq) for seq in raw_sequences]\n",
        "\n",
        "# # Convert to tensor and pad\n",
        "# tensor_sequences = [torch.tensor(seq, dtype=torch.float32) for seq in normalized_sequences]\n",
        "# padded_sequences = pad_sequence(tensor_sequences, batch_first=True)  # [N, T, F]\n",
        "# labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# # STEP 6: Train/val split\n",
        "# X_train, X_val, y_train, y_val = train_test_split(\n",
        "#     padded_sequences, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42\n",
        "# )\n",
        "\n",
        "# # STEP 7: Custom Dataset\n",
        "# class SensorDataset(Dataset):\n",
        "#     def __init__(self, X, y):\n",
        "#         self.X = X\n",
        "#         self.y = y\n",
        "#     def __len__(self):\n",
        "#         return len(self.X)\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.X[idx], self.y[idx]\n",
        "\n",
        "# train_ds = SensorDataset(X_train, y_train)\n",
        "# val_ds = SensorDataset(X_val, y_val)\n",
        "# train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "# val_dl = DataLoader(val_ds, batch_size=32)\n",
        "\n",
        "# # STEP 8: Define LSTM Model\n",
        "# class LSTMClassifier(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, num_classes):\n",
        "#         super().__init__()\n",
        "#         self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "#         self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         _, (h_n, _) = self.lstm(x)\n",
        "#         out = self.fc(h_n[-1])\n",
        "#         return out\n",
        "\n",
        "# # STEP 9: Train\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = LSTMClassifier(input_size=padded_sequences.shape[2], hidden_size=128, num_classes=len(le.classes_)).to(device)\n",
        "\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# for epoch in range(5):  # Increase if needed\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "#     for xb, yb in train_dl:\n",
        "#         xb, yb = xb.to(device), yb.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         preds = model(xb)\n",
        "#         loss = loss_fn(preds, yb)\n",
        "\n",
        "#         # NaN check\n",
        "#         if torch.isnan(loss):\n",
        "#             print(\"NaN loss detected! Aborting training.\")\n",
        "#             break\n",
        "\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "#     else:\n",
        "#         print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_dl):.4f}\")\n",
        "#         continue\n",
        "#     break  # if NaN occurred\n",
        "\n",
        "# # STEP 10: Evaluate\n",
        "# model.eval()\n",
        "# all_preds = []\n",
        "# all_labels = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for xb, yb in val_dl:\n",
        "#         xb = xb.to(device)\n",
        "#         outputs = model(xb)\n",
        "#         preds = torch.argmax(outputs, dim=1).cpu()\n",
        "#         all_preds.extend(preds.numpy())\n",
        "#         all_labels.extend(yb.numpy())\n",
        "\n",
        "# print(\"Validation Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "# print(classification_report(all_labels, all_preds, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Svy-UxT9n9q"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Install and import dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlAH4JOw_wdH"
      },
      "outputs": [],
      "source": [
        "# STEP 2: Load data\n",
        "train_df = pd.read_csv(\"cmi_data/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUoyG-DzBcdP"
      },
      "outputs": [],
      "source": [
        "# STEP 3: Sensor & label columns\n",
        "sensor_start_col = train_df.columns.get_loc('acc_x')\n",
        "sensor_cols = train_df.columns[sensor_start_col:]\n",
        "label_df = train_df[['sequence_id', 'behavior']].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDu5wpaVBeNo"
      },
      "outputs": [],
      "source": [
        "# STEP 4: Encode labels\n",
        "le = LabelEncoder()\n",
        "label_df['label'] = le.fit_transform(label_df['behavior'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWcD3mpJBfnN"
      },
      "outputs": [],
      "source": [
        "# STEP 5: Build sequences and normalize\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "# Collect all sequences for scaling\n",
        "raw_sequences = []\n",
        "for seq_id in label_df['sequence_id']:\n",
        "    seq_data = train_df[train_df['sequence_id'] == seq_id][sensor_cols].values\n",
        "    raw_sequences.append(seq_data)\n",
        "    labels.append(label_df[label_df['sequence_id'] == seq_id]['label'].values[0])\n",
        "\n",
        "# Fit scaler on all sensor data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(np.vstack(raw_sequences))\n",
        "\n",
        "# Normalize each sequence\n",
        "normalized_sequences = [scaler.transform(seq) for seq in raw_sequences]\n",
        "\n",
        "# Convert to tensor and pad\n",
        "tensor_sequences = [torch.tensor(seq, dtype=torch.float32) for seq in normalized_sequences]\n",
        "padded_sequences = pad_sequence(tensor_sequences, batch_first=True)  # [N, T, F]\n",
        "labels_tensor = torch.tensor(labels, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5HzJvPLEtBM"
      },
      "outputs": [],
      "source": [
        "# STEP 6: Train/val split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    padded_sequences, labels_tensor, test_size=0.2, stratify=labels_tensor, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlOfG3qvEus1"
      },
      "outputs": [],
      "source": [
        "# STEP 7: Custom Dataset\n",
        "class SensorDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = SensorDataset(X_train, y_train)\n",
        "val_ds = SensorDataset(X_val, y_val)\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7gWChbYEwT_"
      },
      "outputs": [],
      "source": [
        "# STEP 8: Define LSTM Model\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqwf3yBCExqQ",
        "outputId": "15ec79f1-c327-47e4-db82-dc6a366e77f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN loss detected! Aborting training.\n"
          ]
        }
      ],
      "source": [
        "# STEP 9: Train\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMClassifier(input_size=padded_sequences.shape[2], hidden_size=128, num_classes=len(le.classes_)).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(5):  # Increase if needed\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "\n",
        "        # NaN check\n",
        "        if torch.isnan(loss):\n",
        "            print(\"NaN loss detected! Aborting training.\")\n",
        "            break\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_dl):.4f}\")\n",
        "        continue\n",
        "    break  # if NaN occurred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "911WdzjzISfn"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"lstm_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "R7pUA-tSIaJ5",
        "outputId": "7dda87ce-5868-4d2a-ecb1-d0427f8ca345"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7b73e09a-ae95-4499-94f7-ee4662b99467\", \"lstm_model.pth\", 950886)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"lstm_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "33HPtVC7EzCG",
        "outputId": "b6279434-eace-4150-cad8-d63aa830af0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.4653445103250869\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Number of classes, 3, does not match size of target_names, 4. Try specifying the labels parameter",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-43-603185610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2691\u001b[0m             )\n\u001b[1;32m   2692\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2694\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 3, does not match size of target_names, 4. Try specifying the labels parameter"
          ]
        }
      ],
      "source": [
        "# STEP 10: Evaluate\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        xb = xb.to(device)\n",
        "        outputs = model(xb)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu()\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(yb.numpy())\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "print(classification_report(all_labels, all_preds, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-kl_6ho7OXe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c84e3f90",
        "outputId": "42ce89bb-47b6-4252-f589-da23d14ba4c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] WARNING | pattern 'THIS_IS_WHERE_YOU_PUT_YOUR_NOTEBOOK_PATH' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: THIS_IS_WHERE_YOU_PUT_YOUR_NOTEBOOK_PATH.py",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1024332937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Download the generated Python file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: THIS_IS_WHERE_YOU_PUT_YOUR_NOTEBOOK_PATH.py"
          ]
        }
      ],
      "source": [
        "# Save the notebook as a Python file\n",
        "# IMPORTANT: Replace THIS_IS_WHERE_YOU_PUT_YOUR_NOTEBOOK_PATH with the actual path to your notebook file in Google Drive.\n",
        "# Example: '/content/drive/MyDrive/my_notebook.ipynb'\n",
        "notebook_path = 'THIS_IS_WHERE_YOU_PUT_YOUR_NOTEBOOK_PATH'\n",
        "\n",
        "!jupyter nbconvert --to script \"$notebook_path\"\n",
        "\n",
        "# Get the name of the generated Python file (it will have the same name as the notebook but with a .py extension)\n",
        "import os\n",
        "notebook_name = os.path.basename(notebook_path)\n",
        "python_file_name = os.path.splitext(notebook_name)[0] + '.py'\n",
        "\n",
        "from google.colab import files\n",
        "# Download the generated Python file\n",
        "files.download(python_file_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
